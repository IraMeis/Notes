# Модели представления параллельных алгоритмов

Для непосредственной работы с алгоритмами (синтеза и анализа) исследователь нуждается в средствах их описания, желательно менее формализированных и более удобных для практических целей, чем представляемые в рамках классической теории алгоритмов (машины Тьюринга, Поста и т.п.). В области параллельных вычислений для этого используются собственные модели.

## Модель задача/канал

Популярная модель задача/канал представляет из себя ориентированный граф, пример которого изображен на рис. 1.7.
![[Pasted image 20220612135330.png]]
Задачи изображаются окружностями и содержат наборы инструкций и данных, над которыми инструкции исполняются. Каналы соответствуют дугам на графе и необходимы для пересылки данных между задачами. 

Так, в представленной на рис. 1.7 задаче 3 сначала производится прием данных от задачи 1, затем от задачи 2; после чего запланированы вычисления, завершающиеся отправкой данных задаче 4. 

Внутри одной задачи инструкции исполняются в строгой очередности: одна за другой, как в последовательном алгоритме. Одновременное исполнение инструкций в нескольких задачах обуславливает параллельность вычислений, характеризуя алгоритм, содержащий эти задачи, как параллельный. В ходе работы параллельного алгоритма задачи могут упраздняться и порождаться в соответствии с инструкциями других задач.

Особенностью канала является ориентированность, задающая направление пересылки. Для отправки данных в обратном направлении необходимо организовать другой канал, связывающий те же задачи, но ориентированный противоположно. Отправления по одному каналу производятся по принципу первый вошел – первый вышел.

В соответствии с порядком организации коммуникаций параллельного алгоритма различают следующие их типы, характеризующие данный алгоритм.
### Локальные и глобальные коммуникации
Первые отличаются слабой (не превышающей логарифмической) зависимостью количества соседей выбранной характерной задачи алгоритма от общего числа задач, вторые – более сильной. Так коммуникации алгоритма, повторяющие сетевые конфигурации *процессорная линия*, *кольцо*, *решетка*, *тор*, *бинарное дерево* и *гиперкуб* признают локальными, а *полносвязаную* и *звезду* – глобальными.

### Синхронные и асинхронные коммуникации.
Синхронизация коммуникаций подразумевает определенное согласование действий во время оправки и приема данных внутри отправляющих и принимающих задач, этими коммуникациями связанных. Синхронная отправка и прием исключает производство каких-либо иных действий в отправляющей и принимающей задачах до окончания приема. В ходе асинхронной отправки и приема данных возможно исполнение следующих далее в задачах инструкций до завершения приема. Не исключается ситуация асинхронной отправки и синхронного приема (или наоборот), при которой отправляющая задача не дожидается окончания приема (или принимающая окончания отправки).

### Статические и динамические коммуникации.
Если топология коммуникаций алгоритма не зависит ни от начальных данных, ни от промежуточных результатов расчета, то говорят о статических коммуникациях. В противном случае коммуникации именуют динамическими, возникающими или упраздняющимися в ходе вычислений в зависимости от значений начальных данных либо промежуточных результатов.

### Регулярные и нерегулярные коммуникации
При составлении алгоритма принято ориентироваться на определенный круг доступных разработчику вычислительных комплексов, характеризующихся известным набором сетевых конфигураций. Совпадение топологии коммуникаций алгоритма с известной или планируемой к развертыванию сетевой конфигурацией определяет такие коммуникации как регулярные. В противном случае нерегулярных коммуникаций, реализация алгоритма на любой известной сетевой конфигурации потребует дополнительной маршрутизации через промежуточные вычислительные узлы, что приведет к замедлению расчетов.

## Нотация Джина Голуба
Следующая форма представления алгоритмов Джина Голуба не подменяет, а дополняет предыдущую, позволяя конкретизировать содержание задач. Что не умаляет ее ценность как самостоятельной формы. 

Как и ранее, каждой задаче (Голуб называет задачу процессором, однако позволим себе эту замену) ставится в соответствие свой набор инструкций, который необходимо задать при составлении параллельного алгоритма. Буквально следовать этому правилу, раздельно оформляя инструкции всем задачам, неудобно, особенно если точное количество задач заранее неизвестно. Поэтому для лаконичности параллельного алгоритма принято писать один набор инструкций, предназначая его к исполнению всем задачам. В зависимости от номера задачи, внутри нее исполняются или пропускаются те или иные фрагменты этого набора. Значительная часть фрагментов может исполняться несколькими (даже всеми) задачами одновременно. 

Описание алгоритма делится на две части. Инициализация, в которую вынесены результаты подготовительной стадии расчетов: задание общего количества задач $p$, определение номера конкретной задачи $\mu$, распределение начальных данных по задачам и конкретизация соседей $\mu$-той задачи. 

При программной реализации необходимы известные усилия для подготовки этих данных, однако здесь они считаются уже известными. Вторая часть – собственно алгоритм на языке Голуба, почти совпадающем с синтаксисом MATLAB’а. Например, вектор $a$ длины $n$ записывается как $a(1:n)$, из него можно выбрать все нечетные элементы, указав $a(1:2:n)$; аналогично обозначается квадратная матрица $A(1:n, 1:n)$ и её блок $A(n_{1}:n_{2}, n_{3}:n_{4})$.

Из всех топологий коммуникаций Голуб особо выделяет четыре: линию, кольцо, решетку и тор. В случае одномерной топологии соседи задачи $\mu$ обозначаются за $left, right$; в случае двумерной соседи задачи $(\mu, \lambda)-east, west, north, south$. То есть без учёта крайних задач: $left=\mu-1, right=\mu+1$ в одномерном случае и $east=\mu+1, west=\mu-1, north=\lambda-1, south=\lambda+1$ в двумерном. На кольце для задачи $\mu=1$ левым соседом будет задача $p$, для $\mu=p$ правый сосед – 1. Несложно аналогично определить соседей крайних задач в торе.

Организация коммуникаций в случае сетевой конфигурации (пример распределенной памяти с полносвязной топологией по Хокни у Голуба понимается как вариант сетевой конфигурации) производится посредством введения операций *send*(<*что отправляется*>,<*кому отправляется*>) и *recv*(<*что принимается*>,<*от кого принимается*>). В последней инструкции указание второго аргумента не обязательно, данные уже поступили и их можно принять не зная номера задачи отправителя. Также может быть заранее неизвестен объем принимаемых данных – его допускается определить после приема.

При записи алгоритма на общей памяти инициализация дополняется приведением данных, доступных всем задачам; соседи не упоминаются. В тексте алгоритма локальные данные, находящиеся в распоряжении только одной задачи, помечаются нижним индексом $loc$. Коммуникации между задачами организуются посредством записи в общий участок памяти из локального операцией *put*(<*локальные данные*>,<*общие данные*>) и обратного действия – get(<*общие данные*>,<*локальные данные*>).

Проблема исключения одновременного доступа нескольких задач к одному участку общих данных и возникающая в связи с этим неопределенность решаются в с использованием мониторов, от которых автор отказался в следующем издании монографии (к сожалению не переведенном на русский язык), практикуя там применение критических интервалов. Критический интервал представляет из себя участок алгоритма, обрамленный следующей нотацией
```
begin critical section
	инструкции
end critical section
```
Внутри него исключается одновременное исполнение инструкций несколькими задачами. В критический интервал входит только одна, остальные задерживаются перед ним.

Важным инструментом организации вычислений также является барьерная синхронизация задач параллельного алгоритма. Дойдя до инструкции *barrier* задача прекращает действия до тех пор, пока все остальные также не подойдут к барьеру, не обязательно этому же.

Механизм распределения начальных данных между задачами в инициализации раскрывать не принято, однако результат такого распределения оговорить необходимо. В нотации Голуба различаются линейное и циклическое распределения.

Пусть необходимо распределить $n$ элементов вектора $a(1:n)$ между $p$ задачами. Тогда, положив для простоты, что $n$ делится на $p$ нацело и $r=\frac{n}{p}$, отнесём при линейном распределении к ведению задачи $\mu (1\leq\mu\leq p)$ часть вектора $a((\mu-1)r+1:\mu r)$. Элементы выделенного фрагмента вектора соседствовали друг другу и в векторе $a$. При циклическом распределении $a(\mu: p: n)$ это не так, из $a$ выбираются элементы с шагом $p$. 

Распределение матриц зависит от способа хранения двумерного массива в памяти ЭВМ. Разворачивая его по строкам (например, как в языке си) говорят о строчном хранении, по столбцам (как на фортране) – о столбцовом. В табл. 1.2 представлены варианты линейного и циклического распределения в обоих случаях.
![[Pasted image 20220612140740.png]]

Во второй строке табл. 1.2 задаче $\mu$ достается блочный столбец или строка, в третьей строке – циклический набор столбцов или строк. Случаи специальных схем хранения $A$ (по лентам, блочных и т.п.) пока оставим.

Способ выбора элементов из массива может оказать решающее влияние на длительность вычислений в ходе реализации самого алгоритма, после распределения начальных данных. Очевидна необходимость учета структуры хранения и в этом случае. Ключевым здесь является понятие шага выборки – расстояния между двумя извлекаемыми из массива элементами, измеренное в количестве ячеек. Предпочтительны операции с единичным шагом выборки, характеризующиеся наименьшим временем доступа к данным и лучшей конвейеризацией вычислений. Эта проблема будет подробно освещена при рассмотрении векторных (на практике для производства векторных операций задействуется конвейер) алгоритмов матричных вычислений.

Независимо от типа коммуникаций (сетевых или на общей памяти) при их организации принято соблюдать следующие два правила хорошего тона.
1. . Отправляемые данные должны располагаться в одной области памяти без разрывов. Например, при строчном хранении данных неудачной будет операция $send(A(:, 1), left)$ или $put(A_{loc}(:, 1), 1)$ по пересылке первого столбца матрицы $A$. Ее производство сопряжено с предварительной выборкой элементов этого столбца, характеризующейся неединичным шагом.
2. Необходимо оценить эффективность объединения коммуникационных операций, разумеется при возможности такого объединения. В первом приближении, зависимость длительности коммуникации $T$ от объема пересылаемых данных $V$ имеет линейный характер (рис. 1.8, пунктирная линия). На самом деле (второе приближение), пересылку данных предваряет этап подготовки коммуникации (длительности $t_{1}$ на рис. 1.8), а сама отправка производится дискретными порциями – пакетами (объема $V_{1}$). Длительность передачи одного пакета - $t_{2}$ составляется из времени подготовительного этапа и издержек на собственно пересылку.
![[Pasted image 20220612141030.png]]
При $V<V_{n}$ отправляется все равно целый пакет, график исследуемой зависимости $T(V)$ в силу этого имеет ступенчатый вид. Поэтому небольшие объемы данных выгодно объединять и пересылать одной операцией. В третьем приближении, когда $V \gg V_{п}$, линейная модель коммуникаций становится адекватной, пунктирная прямая на рис. 1.8 будет хорошо аппроксимировать непрерывную ступенчатую и объединение можно не производить.